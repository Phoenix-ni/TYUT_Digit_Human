# Description: è¯­éŸ³è¯†åˆ«æ¨¡å‹
# Author: TYUTåˆ›æ–°å­¦ç¤¾
# Date: 2025-10-4 19ï¼š44
import whisper
from opencc import OpenCC
import re

class ASRModel:
    def __init__(self, model_name="small"):
        self.model = whisper.load_model(model_name)
        self.cc = OpenCC('t2s')
        
    def correct_mixed_language_errors(self, text):
        """ä¿®æ­£ä¸­è‹±æ–‡æ··åˆè¯†åˆ«çš„å¸¸è§é”™è¯¯"""
        correction_rules = {
            r'çˆ±äºº': 'iäºº',
            r'æ„äºº': 'eäºº', 
            r'çˆ±äººä¸çˆ±ç¤¾äº¤': 'iäººä¸çˆ±ç¤¾äº¤',
            r'æ„äººçˆ±ç¤¾äº¤': 'eäººçˆ±ç¤¾äº¤',
            r'mæ¯”ç‰¹': 'MBTI',
            r'm b t i': 'MBTI',
            r'åå…­å‹': '16å‹',
            r'åå…­å‹äººæ ¼': '16å‹äººæ ¼',
            r'm b t': 'MBT',
            r'çˆ±æ„': 'IE',
            r'çˆ±æ„äºº': 'IEäºº',
        }
        
        for wrong, correct in correction_rules.items():
            text = re.sub(wrong, correct, text, flags=re.IGNORECASE)
        
        return text
    
    def transcribe(self, audio_data):
        """è½¬å½•éŸ³é¢‘æ•°æ®ä¸ºæ–‡æœ¬"""
        print("ğŸ”„ æ­£åœ¨è½¬å†™å½•éŸ³...")
        
        try:
            result = self.model.transcribe(
                audio_data,
                language=None,
                task="transcribe", 
                temperature=0.0,
                best_of=3,
                beam_size=3
            )
            
            text = result["text"]
            print(f"åŸå§‹è¯†åˆ«ç»“æœ: {text}")
            
            if text and isinstance(text, str):
                simplified_text = self.cc.convert(text)
                print(f"ç®€ä½“ä¸­æ–‡è½¬æ¢ç»“æœ: {simplified_text}")
                
                corrected_text = self.correct_mixed_language_errors(simplified_text)
                print(f"ä¿®æ­£åç»“æœ: {corrected_text}")
                return corrected_text
            
            return text
            
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {e}")
            return "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•"